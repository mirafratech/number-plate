{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsy0QgSzQWTpbNSIFG8FT+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O-SbpVt3rquU"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","import xml.etree.ElementTree as ET\n","import os \n","import shutil\n","from tqdm import tqdm\n","import yaml\n","import matplotlib.pyplot as plt \n","import torch\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from cv2 import waitKey\n","import torch\n","import numpy as np\n","import time\n","\n","#import pytesseract as pt \n","%matplotlib inline"]},{"cell_type":"code","source":["filenames = []\n","\n","size_props = {\n","    'height':[],\n","    'width':[]\n","}\n","\n","bounding_box_props = {\n","    'xmin':[],\n","    'ymin':[],\n","    'xmax':[],\n","    'ymax':[]\n","}\n","\n","\n","annotations_path = 'annotations'\n","for file in tqdm(os.listdir(annotations_path)):\n","    annotation = ET.parse(os.path.join(annotations_path, file))\n","    filenames.append(os.path.join(annotations_path, file))\n","    size = annotation.find('size')\n","    for name, prop_list in size_props.items():\n","        prop_value = size.find(name).text\n","        size_props[name].append(int(prop_value))\n","    bounding_box = annotation.find('object').find('bndbox')\n","    for name, prop_list in bounding_box_props.items():\n","        prop_value = bounding_box.find(name).text\n","        bounding_box_props[name].append(int(prop_value))"],"metadata":{"id":"17iGAUFNr8ui"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame({\n","    'file':filenames,\n","    'width':size_props['width'],\n","    'height':size_props['height'],\n","    'xmin':bounding_box_props['xmin'],\n","    'ymin':bounding_box_props['ymin'],\n","    'xmax':bounding_box_props['xmax'],\n","    'ymax':bounding_box_props['ymax']\n","})\n","\n","df['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\n","df['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n","\n","df['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\n","df['bb_height'] = (df['ymax'] - df['ymin'])/df['height']"],"metadata":{"id":"cOBcOnuptEt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keeping important columns only \n","yolo_df = df[['file', 'center_x', 'center_y', 'bb_width', 'bb_height']]\n","# Performing 70-15-15 split\n","test_size = int(0.15 * len(df))\n","\n","df_train, df_test = train_test_split(yolo_df, test_size=test_size)\n","df_train, df_val = train_test_split(df_train, test_size=test_size)"],"metadata":{"id":"klEgGQEBwK4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#setting the image path for train, test and validation\n","\n","train_path = os.path.join('Images', 'train')\n","val_path = os.path.join('Images','val')\n","test_path = os.path.join('Images', 'test')\n","lp_path=os.path.join('Images', 'License_plate')\n","images_path = 'images'\n","\n","if not os.path.exists(train_path):\n","    os.makedirs(train_path)\n","    print('Made folder for train set')\n","\n","if not os.path.exists(val_path):\n","    os.makedirs(val_path)\n","    print('Made folder for val set')\n","\n","if not os.path.exists(test_path):\n","    os.makedirs(test_path)\n","    print('Made folder for test set')\n","if not os.path.exists(lp_path):\n","    os.makedirs(lp_path)\n","    print('Made folder for lp set')"],"metadata":{"id":"2yg5ReIKwT4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#moving the images to train test and validation folder\n","\n","print('Moving images for train set')\n","for _, row  in tqdm(df_train.iterrows()):\n","    annotation_path = row['file']\n","    image_name = os.path.split(annotation_path)[-1].replace('.xml','')\n","    image_src = os.path.join(images_path, f'{image_name}.png')\n","    image_dst = os.path.join(train_path, f'{image_name}.png')\n","    shutil.copy2(image_src, image_dst)\n","    label_text = f\"0 {row['center_x']} {row['center_y']} {row['bb_width']} {row['bb_height']}\"\n","    with open(os.path.join(train_path, f'{image_name}.txt'), 'w') as f:\n","        f.write(label_text)\n","print('Done moving images for train set')\n","\n","print('Moving images for val set')\n","for _, row  in tqdm(df_val.iterrows()):\n","    annotation_path = row['file']\n","    image_name = os.path.split(annotation_path)[-1].replace('.xml','')\n","    image_src = os.path.join(images_path, f'{image_name}.png')\n","    image_dst = os.path.join(val_path, f'{image_name}.png')\n","    shutil.copy2(image_src, image_dst)\n","    label_text = f\"0 {row['center_x']} {row['center_y']} {row['bb_width']} {row['bb_height']}\"\n","    with open(os.path.join(val_path, f'{image_name}.txt'), 'w') as f:\n","        f.write(label_text)\n","print('Done moving images for val set')\n","\n","print('Moving images for test set')\n","for _, row  in tqdm(df_test.iterrows()):\n","    annotation_path = row['file']\n","    image_name = os.path.split(annotation_path)[-1].replace('.xml','')\n","    image_src = os.path.join(images_path, f'{image_name}.png')\n","    image_dst = os.path.join(test_path, f'{image_name}.png')\n","    shutil.copy2(image_src, image_dst)\n","    label_text = f\"0 {row['center_x']} {row['center_y']} {row['bb_width']} {row['bb_height']}\"\n","    with open(os.path.join(test_path, f'{image_name}.txt'), 'w') as f:\n","        f.write(label_text)\n","print('Done moving images for test set')"],"metadata":{"id":"_5MXwUgKwrOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cloning the ultralytics yolo repository\n","!git clone https://github.com/ultralytics/yolov5.git"],"metadata":{"id":"swlOGAzZxNI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -r yolov5/requirements.txt"],"metadata":{"id":"mM5l-5MExkh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {\n","    'names':['License Plate'],\n","    'nc':1,\n","    'train':os.path.abspath(train_path),\n","    'val':os.path.abspath(val_path)\n","}\n","\n","with open('data.yaml', 'w') as f:\n","    yaml.dump(data, f)"],"metadata":{"id":"AIKmBbzGxlwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python ./yolov5/train.py --data ./data.yaml  --batch-size 8  --epochs 100 --weights yolov5/yolov5s.pt"],"metadata":{"id":"Dr3HeXArxrnu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fetching the latest runs\n","yolo_path = 'yolov5/runs/train'\n","latest_run = os.listdir(yolo_path)[-1]\n","\n","# Fetching the best weights \n","best_weights = os.path.join(yolo_path, latest_run, 'weights', 'best.pt')\n","\n","# Loading the model with best weights trained on custom data \n","model = torch.hub.load('ultralytics/yolov5', 'custom', best_weights)"],"metadata":{"id":"N23ru67gxy2s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_tesseract_options(psm=7):\n","\t\t# tell Tesseract to only OCR alphanumeric characters\n","\t\talphanumeric = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n","\t\toptions = \"-c tessedit_char_whitelist={}\".format(alphanumeric)\n","\t\t# set the PSM mode\n","\t\toptions += \" --psm {}\".format(psm)\n","\t\t# return the built options string\n","\t\treturn options"],"metadata":{"id":"y4l-N5aNyJ8K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#using OCR for license plate number extraction\n","\n","\n","video_path = r\"TEST.mp4\"  #input video path\n","cpu_or_cuda = \"cuda\"  #choose device; \"cpu\" or \"cuda\"(if cuda is available)\n","device = torch.device(cpu_or_cuda)\n","model = model.to(device)\n","frame = cv2.VideoCapture(video_path)\n","\n","frame_width = int(frame.get(3))\n","frame_height = int(frame.get(4))\n","size = (frame_width, frame_height)\n","writer = cv2.VideoWriter('output_1.avi', \n","                         cv2.VideoWriter_fourcc(*'MJPG'),\n","                         10, size)\n","\n","text_font = cv2.FONT_HERSHEY_PLAIN\n","color= (0,255,0)\n","text_font_scale = 1.25\n","prev_frame_time = 0\n","new_frame_time = 0\n","k = 0\n","# Inference Loop\n","while True:\n","    ret, image = frame.read()\n","    if ret:\n","        output = model(image)\n","        result = np.array(output.pandas().xyxy[0])\n","        j=0\n","        for i in result:\n","            p1 = (int(i[0]),int(i[1]))\n","            p2 = (int(i[2]),int(i[3]))\n","            text_origin = (int(i[0]),int(i[1])-5)\n","            number_plate = image[int(i[1]):int(i[3]),int(i[0]):int(i[2])]\n","            cv2.imwrite('Number_plate/frame'+str(k)+'_'+str(j)+'.png', number_plate)\n","            options = build_tesseract_options(psm=7)\n","\n","            text = pytesseract.image_to_string(number_plate,config=options)\n","\n","            cv2.rectangle(image,p1,p2,color=color,thickness=4)  #drawing bounding boxes\n","            cv2.putText(image,text=f\"{i[-1]} {i[-3]:.2f}\"+\"  \"+ text,org=text_origin,\n","                        fontFace=text_font,fontScale=text_font_scale,\n","                        color=color,thickness=4)  #class and confidence text\n","            j=j+1\n","        new_frame_time = time.time()\n","\n","        fps = 1/(new_frame_time-prev_frame_time)\n","        prev_frame_time = new_frame_time\n","        fps = int(fps)\n","        fps = str(fps)\n","        cv2.putText(image, fps, (7, 70), text_font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n","        writer.write(image)\n","        cv2.imwrite('video_frame1/frame'+str(k)+'.png', image)\n","\n","        cv2_imshow(image)\n","  \n","    else:\n","        break\n","\n","    if waitKey(1) & 0xFF == ord('q'):\n","        break\n","    k=k+1\n","\n","frame.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"neiyMykxyn_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZdIdSNGuy7jT"},"execution_count":null,"outputs":[]}]}